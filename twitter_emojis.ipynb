{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Little experiment in sentiment classification\n",
    " \n",
    " * Pick a large number of tweets that contain `:)` or `:(`\n",
    " * Train a classifier to try to distinguish among them\n",
    " * Pick the classifier's brain to see which are the distinguishing features (words associated with 'happy' and 'unhappy' tweets)\n",
    " \n",
    "# Step 1: Data preparation\n",
    " \n",
    " * Let us grab some tweets\n",
    " * Filter to have either `:)` or `:(` (or any other emoji labeled by me as being happy or unhappy), and sort these tweets to separate datasets\n",
    " * Before training a classifier, we must make sure to remove the emojis themselves from the tweets!!!\n",
    "     * **Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "from json.decoder import JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "4500000\n",
      "Number of tweets: 5000000\n",
      "{'id': 934034922288943104, 'truncated': False, 'extended_entities': {'media': [{'id': 933775395614109696, 'source_status_id_str': '933775963921330176', 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'source_user_id': 61559439, 'expanded_url': 'https://twitter.com/nvidia/status/933775963921330176/video/1', 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'source_status_id': 933775963921330176, 'type': 'video', 'id_str': '933775395614109696', 'sizes': {'large': {'w': 1440, 'h': 720, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 340, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 600, 'resize': 'fit'}}, 'indices': [32, 55], 'source_user_id_str': '61559439', 'video_info': {'aspect_ratio': [2, 1], 'duration_millis': 20087, 'variants': [{'bitrate': 2176000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/vid/1440x720/ajXEdcM8TUAWzdfS.mp4'}, {'content_type': 'application/x-mpegURL', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/pl/x0-H6bqZCnFhuYnv.m3u8'}, {'bitrate': 320000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/vid/360x180/X2LDAS68R6EiFi_M.mp4'}, {'bitrate': 832000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/vid/720x360/yrOI0Zg3Rxljq5Sm.mp4'}]}, 'url': 'https://t.co/Eubtcj5lAP', 'display_url': 'pic.twitter.com/Eubtcj5lAP'}]}, 'timestamp_ms': '1511526253660', 'user': {'id': 3409734675, 'following': None, 'screen_name': 'reBhMachine', 'follow_request_sent': None, 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/3409734675/1510272642', 'profile_sidebar_border_color': '000000', 'is_translator': False, 'contributors_enabled': False, 'profile_link_color': 'FF691F', 'profile_sidebar_fill_color': '000000', 'favourites_count': 421, 'name': 're: BH Machine', 'profile_image_url': 'http://pbs.twimg.com/profile_images/928776308720652288/AlLjCZ02_normal.jpg', 'utc_offset': -28800, 'url': None, 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'verified': False, 'profile_background_color': '000000', 'description': None, 'statuses_count': 210, 'profile_background_tile': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/928776308720652288/AlLjCZ02_normal.jpg', 'geo_enabled': False, 'default_profile': False, 'id_str': '3409734675', 'time_zone': 'Pacific Time (US & Canada)', 'followers_count': 5, 'lang': 'es', 'notifications': None, 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'location': None, 'translator_type': 'none', 'default_profile_image': False, 'listed_count': 0, 'created_at': 'Sun Aug 09 05:17:35 +0000 2015', 'profile_text_color': '000000', 'profile_use_background_image': False, 'friends_count': 17, 'protected': False}, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'possibly_sensitive': False, 'geo': None, 'lang': 'en', 'entities': {'urls': [], 'symbols': [], 'user_mentions': [{'id': 61559439, 'screen_name': 'nvidia', 'id_str': '61559439', 'indices': [3, 10], 'name': 'NVIDIA'}], 'hashtags': [], 'media': [{'id': 933775395614109696, 'source_status_id_str': '933775963921330176', 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'source_user_id': 61559439, 'expanded_url': 'https://twitter.com/nvidia/status/933775963921330176/video/1', 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'source_status_id': 933775963921330176, 'type': 'photo', 'id_str': '933775395614109696', 'sizes': {'large': {'w': 1440, 'h': 720, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 340, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 600, 'resize': 'fit'}}, 'indices': [32, 55], 'source_user_id_str': '61559439', 'url': 'https://t.co/Eubtcj5lAP', 'display_url': 'pic.twitter.com/Eubtcj5lAP'}]}, 'in_reply_to_status_id': None, 'filter_level': 'low', 'text': 'RT @nvidia: Happy Thanksgiving! https://t.co/Eubtcj5lAP', 'favorite_count': 0, 'retweeted_status': {'id': 933775963921330176, 'truncated': False, 'extended_entities': {'media': [{'id': 933775395614109696, 'sizes': {'large': {'w': 1440, 'h': 720, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 340, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 600, 'resize': 'fit'}}, 'indices': [20, 43], 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'video_info': {'aspect_ratio': [2, 1], 'duration_millis': 20087, 'variants': [{'bitrate': 2176000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/vid/1440x720/ajXEdcM8TUAWzdfS.mp4'}, {'content_type': 'application/x-mpegURL', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/pl/x0-H6bqZCnFhuYnv.m3u8'}, {'bitrate': 320000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/vid/360x180/X2LDAS68R6EiFi_M.mp4'}, {'bitrate': 832000, 'content_type': 'video/mp4', 'url': 'https://video.twimg.com/ext_tw_video/933775395614109696/pu/vid/720x360/yrOI0Zg3Rxljq5Sm.mp4'}]}, 'expanded_url': 'https://twitter.com/nvidia/status/933775963921330176/video/1', 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'display_url': 'pic.twitter.com/Eubtcj5lAP', 'type': 'video', 'url': 'https://t.co/Eubtcj5lAP', 'id_str': '933775395614109696'}]}, 'user': {'id': 61559439, 'following': None, 'screen_name': 'nvidia', 'follow_request_sent': None, 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/61559439/1494888580', 'profile_sidebar_border_color': 'FFFFFF', 'is_translator': False, 'contributors_enabled': False, 'profile_link_color': '2276BB', 'profile_sidebar_fill_color': 'DDEEF6', 'favourites_count': 3098, 'name': 'NVIDIA', 'profile_image_url': 'http://pbs.twimg.com/profile_images/467079983936970752/LUOWehvo_normal.jpeg', 'utc_offset': -28800, 'url': 'http://www.nvidia.com', 'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/715809862479908864/USEBbqen.jpg', 'verified': True, 'profile_background_color': 'D5D5D5', 'description': 'The official handle for NVIDIA. Blog: http://blogs.nvidia.com Support: http://nvda.ws/2ei5pio All NVIDIA Social Media: http://nvda.ws/2fVB0Lz', 'statuses_count': 10017, 'profile_background_tile': False, 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/467079983936970752/LUOWehvo_normal.jpeg', 'geo_enabled': True, 'default_profile': False, 'id_str': '61559439', 'time_zone': 'Pacific Time (US & Canada)', 'followers_count': 1281275, 'lang': 'en', 'notifications': None, 'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/715809862479908864/USEBbqen.jpg', 'location': 'Santa Clara, CA', 'translator_type': 'none', 'default_profile_image': False, 'listed_count': 5392, 'created_at': 'Thu Jul 30 18:25:14 +0000 2009', 'profile_text_color': '333333', 'profile_use_background_image': True, 'friends_count': 1671, 'protected': False}, 'source': '<a href=\"https://studio.twitter.com\" rel=\"nofollow\">Media Studio</a>', 'possibly_sensitive': False, 'geo': None, 'lang': 'en', 'entities': {'urls': [], 'symbols': [], 'user_mentions': [], 'hashtags': [], 'media': [{'id': 933775395614109696, 'sizes': {'large': {'w': 1440, 'h': 720, 'resize': 'fit'}, 'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'small': {'w': 680, 'h': 340, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 600, 'resize': 'fit'}}, 'indices': [20, 43], 'media_url_https': 'https://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'expanded_url': 'https://twitter.com/nvidia/status/933775963921330176/video/1', 'media_url': 'http://pbs.twimg.com/ext_tw_video_thumb/933775395614109696/pu/img/FXt2DTTIybRVrxnO.jpg', 'display_url': 'pic.twitter.com/Eubtcj5lAP', 'type': 'photo', 'url': 'https://t.co/Eubtcj5lAP', 'id_str': '933775395614109696'}]}, 'in_reply_to_status_id': None, 'filter_level': 'low', 'text': 'Happy Thanksgiving! https://t.co/Eubtcj5lAP', 'favorite_count': 384, 'contributors': None, 'in_reply_to_screen_name': None, 'in_reply_to_user_id': None, 'retweet_count': 65, 'quote_count': 1, 'id_str': '933775963921330176', 'retweeted': False, 'is_quote_status': False, 'favorited': False, 'place': None, 'coordinates': None, 'created_at': 'Thu Nov 23 19:15:13 +0000 2017', 'in_reply_to_status_id_str': None, 'in_reply_to_user_id_str': None, 'reply_count': 7, 'display_text_range': [0, 19]}, 'contributors': None, 'in_reply_to_screen_name': None, 'in_reply_to_user_id': None, 'retweet_count': 0, 'quote_count': 0, 'id_str': '934034922288943104', 'retweeted': False, 'is_quote_status': False, 'favorited': False, 'place': None, 'coordinates': None, 'created_at': 'Fri Nov 24 12:24:13 +0000 2017', 'in_reply_to_status_id_str': None, 'in_reply_to_user_id_str': None, 'reply_count': 0}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "tweets = []\n",
    "with gzip.open(\"english_tweets_00003.json.gz\", \"rt\") as f:\n",
    "    try:\n",
    "        for line in f:\n",
    "            line = line.strip() # remove leading and trailing whitespoace characters (e.g. \"\\n\")\n",
    "            if not line: # empty line\n",
    "                continue\n",
    "            try:\n",
    "                tweet = json.loads(line) # decode line as python data structure (here: dictionary)\n",
    "                tweets.append(tweet)\n",
    "                \n",
    "                counter += 1\n",
    "                if counter >= 5000000: # maximum number of tweets we are willing to read\n",
    "                    break\n",
    "                if counter%500000==0: # print status every 500,000 tweet\n",
    "                    print(counter)\n",
    "                    \n",
    "            except JSONDecodeError: # broken json, data writer probably died in a middle of the writing process\n",
    "                pass\n",
    "    except: # broken gzip, maybe the machine was shut down or something\n",
    "        pass\n",
    "\n",
    "print(\"Number of tweets:\", len(tweets))\n",
    "print(tweets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: [' :)', 'üòÄ', 'üòÉ', 'üòç']\n",
      "unhappy: [' :(', 'üôÅ', 'üòü', '‚òπ', 'üò•', 'üò¢', 'üò†', '‚ò†', 'üò°']\n"
     ]
    }
   ],
   "source": [
    "import re # regular expressions\n",
    "\n",
    "happy_emojis = [\" :)\", \"\\U0001F600\", \"\\U0001F603\", \"\\U0001F60D\"]\n",
    "\n",
    "unhappy_emojis= [\" :(\", \"\\U0001F641\", \"\\U0001F61F\", \"\\u2639\", \"\\U0001F625\", \\\n",
    "                 \"\\U0001F622\", \"\\U0001F620\", \"\\u2620\", \"\\U0001F621\"]\n",
    "\n",
    "print(\"happy:\", happy_emojis)\n",
    "print(\"unhappy:\", unhappy_emojis)\n",
    "\n",
    "# compile lists into regular expressions for fast search\n",
    "happy_regex = re.compile(\"|\".join(re.escape(e) for e in happy_emojis))\n",
    "unhappy_regex = re.compile(\"|\".join(re.escape(e) for e in unhappy_emojis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy: 69337\n",
      "['RED VELVET SEASON GREETING PREVIEW üòç https://t.co/4K6n1CnUik', '@fukayaqui @DonnaFins @redsand2 @SewingAngela @rosevine3 @kigi_ebooks @awlasky @mank56 Thank you, Aki! Happy Friday everyone! üòÄ', 'Why so hot, Nicomaine? üòç\\n\\n¬© mainedcm | IGS\\n#ADNTimeless2017 https://t.co/9MH5mIgJZl', '@PawanKalyan #Kalyan babu launched d T of #2Countries at #PSPK25 Sets üòç\\nFight sequence na endi samee shoot,pillodiki chematalu padday üôèüôè\\n@mee_sunil https://t.co/wTXIC7Kyh3', 'workin on me :) https://t.co/kjdytM1WSt']\n",
      "Unhappy: 21034\n",
      "[\"Likey is ranked 3rd on Music Bank this week!\\n\\ni can't decide between üò¢ or üéâ tbh https://t.co/HU8AcoGB8j\", 'I just checked the headphone I bought in traffic, somewhere around Oshodi last night . They wrote Beats by Dele Ladipo. But why?üò¢', 'but we don‚Äôt get to talk all that much so :(( https://t.co/9OZAvTwToR', 'Need to stop looking at the sales :(', 'GAMEDAY! The 2017 season comes to a close today when we host @American_VBall rival Cincinnati at 1 p.m. Help us send out our seniors in style! #GoPirates #ThankYouSeniors ‚ò†Ô∏è‚ò†Ô∏è‚ò†Ô∏è https://t.co/9x0eQpKtfA']\n"
     ]
    }
   ],
   "source": [
    "happy_tweets = []\n",
    "unhappy_tweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    \n",
    "    if \"retweeted_status\" in tweet:\n",
    "        tweet = tweet[\"retweeted_status\"] # get the original text rather than one with RT: marker\n",
    "    \n",
    "    if tweet.get(\"truncated\"): # text field may be truncated, get the full text\n",
    "        text = tweet[\"extended_tweet\"][\"full_text\"]\n",
    "    else:\n",
    "        text = tweet[\"text\"] # not truncated\n",
    "        \n",
    "    # search for happy and unhappy emojis\n",
    "    if re.search(happy_regex, text) and re.search(unhappy_regex, text): # contains both, skip\n",
    "        continue\n",
    "    elif re.search(happy_regex, text): # happy\n",
    "        happy_tweets.append(text)\n",
    "    elif re.search(unhappy_regex, text): # unhappy\n",
    "        unhappy_tweets.append(text)\n",
    "    \n",
    "print(\"Happy:\", len(happy_tweets))\n",
    "print(happy_tweets[:5])\n",
    "\n",
    "print(\"Unhappy:\", len(unhappy_tweets))\n",
    "print(unhappy_tweets[:5])\n",
    "\n",
    "del tweets # free memory, we do not need all 5M tweets anymore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Preprocessing\n",
    " \n",
    " * Get rid of the emojis\n",
    " * Get rid of line breaks (in case a tweet has multiple lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy: 21034\n",
      "['RED VELVET SEASON GREETING PREVIEW https://t.co/4K6n1CnUik', '@fukayaqui @DonnaFins @redsand2 @SewingAngela @rosevine3 @kigi_ebooks @awlasky @mank56 Thank you, Aki! Happy Friday everyone!', 'Why so hot, Nicomaine? ¬© mainedcm | IGS #ADNTimeless2017 https://t.co/9MH5mIgJZl', '@PawanKalyan #Kalyan babu launched d T of #2Countries at #PSPK25 Sets Fight sequence na endi samee shoot,pillodiki chematalu padday üôèüôè @mee_sunil https://t.co/wTXIC7Kyh3', 'workin on me https://t.co/kjdytM1WSt']\n",
      "Unhappy: 21034\n",
      "[\"Likey is ranked 3rd on Music Bank this week! i can't decide between or üéâ tbh https://t.co/HU8AcoGB8j\", 'I just checked the headphone I bought in traffic, somewhere around Oshodi last night . They wrote Beats by Dele Ladipo. But why?', 'but we don‚Äôt get to talk all that much so ( https://t.co/9OZAvTwToR', 'Need to stop looking at the sales', 'GAMEDAY! The 2017 season comes to a close today when we host @American_VBall rival Cincinnati at 1 p.m. Help us send out our seniors in style! #GoPirates #ThankYouSeniors Ô∏è Ô∏è Ô∏è https://t.co/9x0eQpKtfA']\n"
     ]
    }
   ],
   "source": [
    "processed_happy = []\n",
    "for tweet in happy_tweets: # use the happy emoji regular expression to remove all occurances of those emojis\n",
    "    text = re.sub(happy_regex, \" \", tweet)\n",
    "    processed_happy.append(\" \".join(text.split())) # normalize spaces\n",
    "\n",
    "processed_unhappy = []\n",
    "for tweet in unhappy_tweets:\n",
    "    text = re.sub(unhappy_regex, \" \", tweet)\n",
    "    processed_unhappy.append(\" \".join(text.split()))\n",
    "    \n",
    "processed_happy = processed_happy[:min(len(processed_happy)-1,len(processed_unhappy))] # balance datasets\n",
    "    \n",
    "print(\"Happy:\", len(processed_happy))\n",
    "print(processed_happy[:5])\n",
    "\n",
    "print(\"Unhappy:\", len(processed_unhappy))\n",
    "print(processed_unhappy[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t√§ss√§', 'twiittasin', 'ja', 'joku', 'mummo', 'tuli', 'kysyy', 'multa', 'l√∂ytyyk√∂', 'niit√§', 'pokemoneja', '.', ':)', 'üòÉ', 'üòÉ']\n",
      "Accuracy= 80.79391490373187\n",
      "Majority baseline= 50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [word for word in re.split('([^a-zA-Z√§√•√∂√Ñ√Ö√ñ\\:\\)-])', text) if word != \"\" and word != \" \"]\n",
    "\n",
    "# Turn the text into vectors that can be handled by the classifier\n",
    "vectorizer = TfidfVectorizer(lowercase=True, binary=True, stop_words=None, tokenizer=tokenizer, min_df=20)\n",
    "\n",
    "analyser = vectorizer.build_analyzer() # example of the vectorizer output in text format\n",
    "print(analyser('T√§ss√§ twiittasin ja joku mummo tuli kysyy multa l√∂ytyyk√∂ niit√§ pokemoneja. :) üòÉüòÉ'))\n",
    "\n",
    "# turn text into feature vectors (numbers)\n",
    "data_matrix = vectorizer.fit_transform(processed_happy + processed_unhappy) # run vectorizer\n",
    "\n",
    "# Give each document the target label to be predicted (1 or -1)\n",
    "labels = [1]*len(processed_happy) + [-1]*len(processed_unhappy)\n",
    "\n",
    "# Split data into train and test, keep random 10% of the data aside for testing\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(data_matrix, labels, test_size=0.1, random_state=0)\n",
    "\n",
    "# Train the classifier on our data\n",
    "# C is an important parameter: the smaller, the fewer features will be used\n",
    "classifier=LinearSVC(C=0.05 ,dual=False, penalty='l1', max_iter=100000)\n",
    "classifier.fit(data_train, labels_train)\n",
    "\n",
    "# And test its accuracy on test data\n",
    "print(\"Accuracy=\", classifier.score(data_test, labels_test)*100.0)\n",
    "print(\"Majority baseline=\",max(len(processed_happy), \\\n",
    "                               len(processed_unhappy))/(len(processed_happy) + len(processed_unhappy))*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Pick the classifier's brain\n",
    " \n",
    " * List features with extremely high (associated with positive labels) or extremely low (associated with negative labels) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unhappy features:\n",
      "Ô∏è -3.213200812327916\n",
      "üíî -2.7936901473929105\n",
      "üòî -2.52605848507915\n",
      "„ÉÑ -2.421889597156168\n",
      "sad -2.2633317611939905\n",
      "( -2.1081233179747865\n",
      "üèÜ -1.8224674494627895\n",
      "cry -1.7055506360336716\n",
      "miss -1.645874919653571\n",
      "rest -1.4808243871634572\n",
      "trump -1.4134451500518703\n",
      "not -1.3340863069700946\n",
      "poor -1.3304624810619265\n",
      "missing -1.296803639209172\n",
      "crying -1.2233118530402833\n",
      "ak- -1.2228342492992075\n",
      "wtf -1.1891008991962468\n",
      "üò§ -1.1768903694456319\n",
      "heart -1.1189842862684827\n",
      "broke -1.1025202732437267\n",
      "lost -1.0931192369705716\n",
      "rip -1.0773443575745214\n",
      "sorry -1.0677655506865638\n",
      "was -1.0635753974082085\n",
      "pls -1.0497851221321184\n",
      "but -1.0228162639971374\n",
      "üëé -1.0122700587900884\n",
      "he -1.0085128526804634\n",
      "xwjhh -0.9932680750795008\n",
      "been -0.9832236146630627\n",
      "i -0.9557923884838099\n",
      "hate -0.9170271016052908\n",
      "tears -0.9029342551578683\n",
      "why -0.8910304538107255\n",
      "no -0.8599303259820026\n",
      "libya -0.8292131128617948\n",
      "please -0.8214080684553509\n",
      "help -0.8205372553209255\n",
      "what -0.8083474355563263\n",
      "still -0.7965884754441235\n",
      "------------------------\n",
      "Happy features:\n",
      "‚ù§ 2.1319488760436607\n",
      ") 1.9990632901257117\n",
      "co 1.868857136379089\n",
      "üòò 1.7839931047577744\n",
      "bracelets 1.6771565374955741\n",
      "adntimeless 1.6082329558375295\n",
      "üî• 1.5851433125247014\n",
      "missuniverse 1.5722848218327932\n",
      "üòä 1.3743876465394478\n",
      "üëç 1.3704826054890729\n",
      "happy 1.3344302076232775\n",
      ")) 1.310797861801685\n",
      "ü§§ 1.2112637730855886\n",
      "! 1.2007897753072985\n",
      "new 1.1977662203290111\n",
      "pictures 1.1458046589924278\n",
      "love 1.1332985561187894\n",
      "cool 1.1291897927192498\n",
      "thanks 1.0826003246920586\n",
      "amazing 1.0645784058823646\n",
      "good 1.0530983317081144\n",
      "üëå 1.0509212209639818\n",
      "üò© 1.0456265883081886\n",
      "sale 1.0231344856168119\n",
      "‚ò∫ 1.0171456590041776\n",
      "üéÅ 1.0088088552648273\n",
      "beauty 1.0046811163011138\n",
      "great 0.9711394730813999\n",
      "perfect 0.9681532108742978\n",
      "# 0.959358689589468\n",
      "excited 0.9415461590112032\n",
      "dope 0.9206844281663694\n",
      "beautiful 0.9128671910681396\n",
      "cute 0.8788105555302342\n",
      "% 0.8762426532362542\n",
      "üòé 0.8602601257783581\n",
      "roll 0.8581570178631768\n",
      "‚ô• 0.8510586631586511\n",
      "best 0.8463604171770839\n",
      "listen 0.8398107056513099\n"
     ]
    }
   ],
   "source": [
    "# Print sorted by weight\n",
    "f_names = vectorizer.get_feature_names() # feature names i.e. words \n",
    "sorted_by_weight = sorted(zip(classifier.coef_[0], f_names))\n",
    "\n",
    "# Fourty lowest\n",
    "print(\"Unhappy features:\")\n",
    "for f_weight,f_name in sorted_by_weight[:40]:\n",
    "    print(f_name, f_weight)\n",
    "print(\"------------------------\")\n",
    "# Fourty highest\n",
    "print(\"Happy features:\")\n",
    "for f_weight,f_name in sorted(sorted_by_weight[-40:],reverse=True):\n",
    "    print(f_name, f_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpcourse",
   "language": "python",
   "name": "nlpcourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
